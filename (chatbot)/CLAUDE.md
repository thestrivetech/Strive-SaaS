# CLAUDE-CHATBOT.md

**Claude's Session Memory | v1.0 | Chatbot Project Standards**

> ## ğŸ”´ CRITICAL: READ-BEFORE-EDIT MANDATE
>
> **YOU MUST FOLLOW THESE STEPS BEFORE ANY ACTION:**
>
> 1. **READ FIRST** - Always use Read tool on any file before editing it
> 2. **SEARCH FOR EXISTING** - Use Glob/Grep to check if files, scripts, or tests already exist
> 3. **UPDATE, DON'T CREATE** - Prefer editing existing files over creating new ones (99% of the time)
> 4. **ASK IF UNCERTAIN** - When unsure if something exists, ask the user first
>
> **For root project documentation:**
> - Main standards: [`../CLAUDE.md`](../CLAUDE.md) - Core development rules
> - Project overview: [`../README.md`](../README.md) - Repository structure

---

## ğŸ¯ PROJECT: Strive AI Chatbot (Sai)

**Location:** `(chatbot)/` â†’ chatbot.strivetech.ai (Next.js project)
**Stack:** Next.js 15.6.0 + React 19.1.0 + TypeScript + OpenRouter/Groq + RAG
**Focus:** Embeddable AI assistant with industry-specific knowledge bases

> **Purpose:** Two deployment modes:
> 1. **Widget** - Embeddable `<script>` tag for any website
> 2. **Standalone** - Full-page chat interface at chatbot.strivetech.ai

---

## âš¡ TECH STACK

```yaml
Core: Next.js 15.6.0, React 19.1.0, TypeScript 5.6+

# AI & RAG
AI Gateway: OpenRouter (GPT-4, Claude 3.5, Llama 3.3)
Fast Inference: Groq (Llama 3.3, Mixtral, Gemma)
Vector DB: Supabase pgvector
Embeddings: OpenAI text-embedding-3-small

# Backend
Database: Supabase PostgreSQL
ORM: Prisma 6.16.2 (connects to Supabase)
Auth: API key based (for widget)
Storage: Supabase Storage

# Frontend
UI: shadcn/ui + Radix UI + Tailwind CSS
State: TanStack Query + Zustand
Forms: React Hook Form + Zod
Streaming: Server-Sent Events (SSE)

Testing: Jest + React Testing Library (80% min)
```

**IMPORTANT:** RAG (Retrieval Augmented Generation) is core to this project:
- **RAG** = Semantic search over knowledge base + AI generation
- **pgvector** = PostgreSQL extension for vector similarity search
- **Embeddings** = Text converted to 1536-dimensional vectors

---

## ğŸ“ STRUCTURE

```
(chatbot)/
â”œâ”€â”€ app/                      # Next.js App Router
â”‚   â”œâ”€â”€ layout.tsx           # Root layout (REQUIRED)
â”‚   â”œâ”€â”€ page.tsx             # Root page (redirects to /full)
â”‚   â”œâ”€â”€ globals.css          # Global styles
â”‚   â”œâ”€â”€ full/                # Standalone chat interface
â”‚   â”‚   â””â”€â”€ page.tsx
â”‚   â”œâ”€â”€ widget/              # Embeddable widget
â”‚   â”‚   â””â”€â”€ page.tsx
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ chat/           # Streaming chat endpoint
â”‚   â”‚   â””â”€â”€ embed/          # Widget embed script
â”‚   â”œâ”€â”€ constants/          # App constants
â”‚   â”œâ”€â”€ features/           # Feature components
â”‚   â”‚   â”œâ”€â”€ ai-chat.tsx
â”‚   â”‚   â”œâ”€â”€ chat-input.tsx
â”‚   â”‚   â””â”€â”€ message-bubble.tsx
â”‚   â”œâ”€â”€ industries/         # Industry customizations
â”‚   â”‚   â”œâ”€â”€ real-estate/
â”‚   â”‚   â”‚   â”œâ”€â”€ config.json
â”‚   â”‚   â”‚   â”œâ”€â”€ system-prompt.ts
â”‚   â”‚   â”‚   â””â”€â”€ solutions.ts
â”‚   â”‚   â””â”€â”€ strive/
â”‚   â”œâ”€â”€ schemas/            # Zod validation
â”‚   â””â”€â”€ services/
â”‚       â”œâ”€â”€ cache-service.ts
â”‚       â””â”€â”€ rag-service.ts
â”œâ”€â”€ components/
â”‚   â””â”€â”€ ui/                 # shadcn components
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ ai/                 # AI integration
â”‚   â”‚   â”œâ”€â”€ client.ts      # OpenRouter/Groq clients
â”‚   â”‚   â”œâ”€â”€ chat.ts        # Chat completion logic
â”‚   â”‚   â””â”€â”€ streaming.ts   # SSE streaming
â”‚   â”œâ”€â”€ rag/                # RAG system
â”‚   â”‚   â”œâ”€â”€ embeddings.ts  # Generate embeddings
â”‚   â”‚   â”œâ”€â”€ search.ts      # Vector similarity search
â”‚   â”‚   â””â”€â”€ context.ts     # Build context from results
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â””â”€â”€ prisma.ts      # Prisma client
â”‚   â”œâ”€â”€ supabase/
â”‚   â”‚   â””â”€â”€ client.ts      # Supabase client
â”‚   â””â”€â”€ utils/              # Helper functions
â”œâ”€â”€ types/                  # TypeScript types
â”‚   â”œâ”€â”€ api.ts
â”‚   â”œâ”€â”€ conversation.ts
â”‚   â”œâ”€â”€ industry.ts
â”‚   â””â”€â”€ rag.ts
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ generate-embeddings.ts    # Populate vector DB
â”‚   â””â”€â”€ test-vector-search.ts     # Test RAG
â”œâ”€â”€ __tests__/              # Test suites
â”œâ”€â”€ SUPABASE-RAG-SETUP.sql         # Vector DB schema
â””â”€â”€ middleware.ts           # API key validation
```

---

## ğŸ”´ CRITICAL RULES - CHATBOT SPECIFIC

### RAG System Best Practices

**1. Vector Search Quality**
```typescript
// âœ… ALWAYS use similarity threshold
const results = await searchKnowledge(query, {
  industry: 'real-estate',
  threshold: 0.7,  // Minimum similarity score
  limit: 5,
});

// âŒ NEVER return low-quality matches
const badResults = await searchKnowledge(query, {
  threshold: 0.3,  // Too low - returns irrelevant content
});
```

**2. Embedding Generation**
```typescript
// âœ… Batch embeddings for efficiency
const embeddings = await generateEmbeddings([text1, text2, text3]);

// âŒ NEVER generate one at a time in loop
for (const text of texts) {
  await generateEmbedding(text); // Slow!
}
```

**3. Context Window Management**
```typescript
// âœ… Limit context to fit model's window
const context = buildContext(results, {
  maxTokens: 2000,  // Leave room for prompt + response
  industry,
});

// âŒ NEVER exceed model's context limit
const tooMuchContext = results.map(r => r.content).join('\n'); // Can exceed 4096 tokens
```

### AI Provider Patterns

**1. Model Selection**
```typescript
// âœ… Use appropriate model for task
const FREE_TIER = 'llama-3.3-70b-versatile';      // Groq - fast, free
const PAID_TIER = 'gpt-4-turbo-preview';          // OpenRouter - capable
const PREMIUM_TIER = 'anthropic/claude-3.5-sonnet'; // Best quality

// Choose based on user tier
const model = user.tier === 'free' ? FREE_TIER : PAID_TIER;
```

**2. Streaming Responses**
```typescript
// âœ… ALWAYS stream for better UX
export const runtime = 'edge';

export async function POST(req: Request) {
  const stream = await chat(messages, { stream: true });

  return new Response(stream, {
    headers: {
      'Content-Type': 'text/event-stream',
      'Cache-Control': 'no-cache',
    },
  });
}

// âŒ NEVER wait for full response
const fullResponse = await chat(messages, { stream: false }); // Slow UX
```

**3. Error Handling**
```typescript
// âœ… Graceful fallback for AI failures
try {
  const response = await chat(messages, { model: 'gpt-4' });
  return response;
} catch (error) {
  // Fallback to faster/cheaper model
  return await chat(messages, { model: 'llama-3.3-70b' });
}
```

### Widget Embedding Standards

**1. Widget Initialization**
```typescript
// âœ… Isolate widget styles
const Widget = () => (
  <div className="sai-widget" style={{ all: 'initial' }}>
    <style>{isolatedStyles}</style>
    <ChatInterface />
  </div>
);

// âŒ NEVER pollute parent page styles
const BadWidget = () => (
  <div className="chat"> {/* Conflicts with parent CSS */}
    <ChatInterface />
  </div>
);
```

**2. API Key Security**
```typescript
// âœ… Validate API key server-side
export async function POST(req: Request) {
  const apiKey = req.headers.get('x-api-key');
  const isValid = await validateApiKey(apiKey);
  if (!isValid) return new Response('Unauthorized', { status: 401 });
  // ...
}

// âŒ NEVER trust client-provided keys
const apiKey = searchParams.get('key'); // Can be stolen!
```

**3. CORS Configuration**
```typescript
// âœ… Allow specific domains
export async function OPTIONS(req: Request) {
  const origin = req.headers.get('origin');
  const isAllowed = await checkAllowedDomain(origin);

  return new Response(null, {
    headers: {
      'Access-Control-Allow-Origin': isAllowed ? origin : '',
      'Access-Control-Allow-Methods': 'POST',
    },
  });
}
```

### Industry Customization

**1. System Prompts**
```typescript
// âœ… Load industry-specific prompts
const config = await getIndustryConfig(industry);
const systemPrompt = config.systemPrompt || DEFAULT_PROMPT;

const messages = [
  { role: 'system', content: systemPrompt },
  ...userMessages,
];
```

**2. Knowledge Filtering**
```typescript
// âœ… Filter by industry in vector search
const results = await supabase.rpc('search_knowledge', {
  query_embedding: embedding,
  filter_industry: 'healthcare',  // Only healthcare content
  match_count: 5,
});
```

---

## ğŸ”’ SECURITY MANDATES - CHATBOT SPECIFIC

```typescript
// 1. API Key Authentication
const apiKey = req.headers.get('x-api-key');
if (!apiKey || !await validateKey(apiKey)) {
  return new Response('Unauthorized', { status: 401 });
}

// 2. Rate Limiting (per API key)
const { success } = await rateLimit(apiKey);
if (!success) {
  return new Response('Too Many Requests', { status: 429 });
}

// 3. Input Sanitization (prevent prompt injection)
const sanitized = sanitizeUserInput(message);
if (sanitized.length > 2000) {
  return new Response('Message too long', { status: 400 });
}

// 4. Output Filtering (prevent leaked secrets)
const response = await chat(messages);
const filtered = filterSensitiveInfo(response);

// 5. CORS Restrictions
const allowedOrigins = await getAllowedOrigins(apiKey);
if (!allowedOrigins.includes(origin)) {
  return new Response('Forbidden', { status: 403 });
}
```

**NEVER expose:**
- OpenRouter/Groq API keys
- Supabase Service Role Key
- Database credentials
- Other users' conversations

---

## ğŸš€ PERFORMANCE TARGETS - CHATBOT

```yaml
# Streaming Performance
First Token: < 500ms      # Time to first AI response token
Token Rate: > 50/sec      # Streaming speed

# RAG Performance
Vector Search: < 100ms    # Similarity search time
Embedding Gen: < 200ms    # Time to generate query embedding

# Widget Performance
Load Time: < 500ms        # Widget initialization
Bundle Size: < 150kb      # Widget JavaScript bundle

# Overall
Chat Response: < 2s       # End-to-end (search + AI)
```

**Optimization Patterns:**
```typescript
// 1. Cache embeddings (avoid regeneration)
const cached = await redis.get(`embed:${text.hash()}`);
if (cached) return JSON.parse(cached);

// 2. Parallel RAG + AI
const [ragResults, aiStream] = await Promise.all([
  searchKnowledge(query),
  initiateChatStream(messages),
]);

// 3. Edge runtime for low latency
export const runtime = 'edge';
```

---

## âœ… PRE-COMMIT CHECKLIST - CHATBOT

**MANDATORY before ANY commit:**
```bash
npm run lint        # Zero warnings
npm run type-check  # Zero errors
npm test            # 80% coverage minimum
```

**Chatbot-Specific Checks:**
- [ ] RAG search returns relevant results (similarity > 0.7)
- [ ] AI responses stream properly (first token < 500ms)
- [ ] Widget loads without CSS conflicts
- [ ] API keys validated server-side
- [ ] Rate limiting enforced
- [ ] Industry knowledge bases accurate
- [ ] No exposed secrets in code

**Test Coverage Requirements:**
- RAG system: 90%
- AI integration: 85%
- Widget embedding: 80%
- API routes: 100%
- Overall: 80% minimum

---

## ğŸ›  COMMANDS - CHATBOT

```bash
# Setup
npm install
npx prisma generate
npm run rag:setup              # Setup pgvector database

# Development
npm run dev                     # Start dev server
npm run rag:generate-embeddings # Populate knowledge base
npm run rag:test-search        # Test vector search

# Pre-commit (ALWAYS)
npm run lint && npm run type-check && npm test

# RAG Management
npm run rag:setup              # Initialize vector DB
npm run rag:generate-embeddings # Generate embeddings
npm run rag:test-search        # Test similarity search

# Testing
npm test                       # Run all tests
npm test -- --coverage         # With coverage
npm test rag                   # Test RAG system
npm test ai                    # Test AI integration
```

---

## ğŸ¯ CORE PRINCIPLES - CHATBOT

1. **RAG-first** - Always use knowledge base for grounded responses
2. **Stream everything** - Token-by-token for perceived speed
3. **Industry-aware** - Customize responses per industry
4. **Widget-friendly** - Isolated styles, minimal bundle size
5. **API key security** - Never expose keys, validate server-side
6. **Model flexibility** - Support multiple AI providers
7. **Quality threshold** - Only return relevant RAG results (>0.7 similarity)
8. **Production mindset** - Every token costs money

---

## ğŸ“‹ RAG WORKFLOW

**Knowledge Base Population:**
```bash
# 1. Prepare content (markdown, JSON, etc.)
# 2. Generate embeddings
npm run rag:generate-embeddings

# 3. Verify in database
npx prisma studio
# Check chatbot_knowledge table

# 4. Test search
npm run rag:test-search
```

**Query Flow:**
```
User Query
    â†“
Generate Query Embedding (200ms)
    â†“
Vector Similarity Search (100ms)
    â†“
Build Context from Top 5 Results
    â†“
Send to AI Model with Context
    â†“
Stream Response to User
```

---

## âŒ NEVER DO THIS - CHATBOT

```typescript
// RAG Anti-patterns
âŒ return allResults;  // Without similarity threshold
âŒ const embedding = await embed(text); // In a loop (use batch)
âŒ const context = results.join('\n'); // Without token limit

// AI Anti-patterns
âŒ const response = await chat({ stream: false }); // Non-streaming
âŒ const gpt4 = await chat({ model: 'gpt-4' }); // For all users (expensive)
âŒ return aiResponse; // Without filtering sensitive info

// Widget Anti-patterns
âŒ <div className="chat"> // Generic class names (conflicts)
âŒ const key = params.get('key'); // Client-side API key
âŒ document.body.innerHTML = widget; // Pollutes parent page

// Security Anti-patterns
âŒ const apiKey = process.env.OPENROUTER_KEY; // Exposed to client
âŒ await chat({ messages: userInput }); // Without sanitization
âŒ return new Response(result); // Without CORS check
```

---

## ğŸ”— QUICK REFS - CHATBOT

- **AI Models:**
  - Free: `llama-3.3-70b-versatile` (Groq)
  - Standard: `gpt-4-turbo-preview` (OpenRouter)
  - Premium: `anthropic/claude-3.5-sonnet` (OpenRouter)

- **RAG Config:**
  - Embedding model: `text-embedding-3-small`
  - Vector dimensions: 1536
  - Similarity threshold: 0.7
  - Context limit: 2000 tokens

- **Industries:**
  - Real Estate
  - Healthcare
  - Strive (general)
  - Custom (per client)

---

## ğŸ¯ DECISION TREE - CHATBOT

**Before you start:**
1. **Check RAG setup** â†’ Is vector DB initialized?
2. **Check API keys** â†’ Are OpenRouter/Groq keys set?
3. **Check knowledge base** â†’ Are embeddings generated?

**During implementation:**
- **Need to query knowledge?** â†’ Use RAG search with threshold
- **Need AI response?** â†’ Stream from appropriate model
- **Need to embed widget?** â†’ Isolate styles, validate API key
- **Adding industry?** â†’ Create industry folder with config
- **Need to cache?** â†’ Use Redis for embeddings/responses

**Before committing:**
- [ ] RAG search tested and accurate
- [ ] AI streaming works
- [ ] Widget loads without conflicts
- [ ] API keys secured
- [ ] Rate limiting enforced
- [ ] 80%+ test coverage

---

**Remember:** This is AI infrastructure. Quality > Speed. Every API call costs money. Cache aggressively.
