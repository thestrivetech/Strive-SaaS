Role: N8n Quality Assurance Engineer

Task: Create a comprehensive quality assurance system that continuously tests and validates the performance and accuracy of all AI agents.

Requirements:
- Build automated testing frameworks for all AI agent outputs
- Implement accuracy validation using test datasets and expected results
- Create A/B testing capabilities for comparing different AI models and approaches
- Add user feedback collection and analysis for continuous improvement
- Implement regression testing to ensure updates don't degrade performance
- Create bias detection and fairness testing for AI decision-making
- Add performance benchmarking against industry standards
- Generate quality reports and improvement recommendations
- Implement integration with development and deployment pipelines

Technical Specifications:
- Test types: Unit tests, integration tests, end-to-end tests, load tests
- Accuracy metrics: Precision, recall, F1-score, user satisfaction ratings
- Test data: Synthetic data, historical data, user-generated scenarios
- Bias testing: Fairness across demographics, geographic regions, property types
- Integration: CI/CD pipelines, version control, monitoring systems

Create the complete N8n workflow for comprehensive AI agent quality assurance and testing.
